{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160991b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    class BinaryClassificationCNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(BinaryClassificationCNN, self).__init__()\n",
    "            \n",
    "            # 첫 번째 Convolutional 레이어: 3개의 입력 채널(RGB), 32개의 출력 채널, 2*2 커널\n",
    "            self.conv1 = nn.Conv2d(3, 32, kernel_size=2, padding=1)\n",
    "            # 두 번째 Convolutional 레이어\n",
    "            self.conv2 = nn.Conv2d(32, 64, kernel_size=2, padding=1)\n",
    "            # 세 번째 Convolutional 레이어\n",
    "            self.conv3 = nn.Conv2d(64, 128, kernel_size=2, padding=1)\n",
    "            \n",
    "            # Pooling 레이어\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            \n",
    "            # Dropout 레이어\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "            \n",
    "            # 첫 번째 Fully Connected 레이어\n",
    "            self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
    "            \n",
    "            # 두 번째 Fully Connected 레이어\n",
    "            self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            # Convolutional 레이어와 활성화 함수 적용\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = self.pool(x)\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = self.pool(x)\n",
    "            x = F.relu(self.conv3(x))\n",
    "            x = self.pool(x)\n",
    "            # Flatten\n",
    "            x = x.view(-1, 128 * 4 *4)\n",
    "            # Dropout 적용\n",
    "            x = self.dropout(x)\n",
    "            # Fully Connected 레이어와 활성화 함수 적용\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.dropout(x)\n",
    "            # 출력 레이어\n",
    "            x = torch.sigmoid(self.fc2(x))\n",
    "            return x\n",
    "\n",
    "    # 모델 인스턴스화\n",
    "    model = BinaryClassificationCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf6520b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [0/1044], Loss: 0.9720\n",
      "Epoch [1/10], Step [100/1044], Loss: 0.6931\n",
      "Epoch [1/10], Step [200/1044], Loss: 0.6931\n",
      "Epoch [1/10], Step [300/1044], Loss: 0.6931\n",
      "Epoch [1/10], Step [400/1044], Loss: 0.6931\n",
      "Epoch [1/10], Step [500/1044], Loss: 0.6931\n",
      "Epoch [1/10], Step [600/1044], Loss: 0.6931\n",
      "Epoch [1/10], Step [700/1044], Loss: 0.6931\n",
      "Epoch [1/10], Step [800/1044], Loss: 0.6931\n",
      "Epoch [1/10], Step [900/1044], Loss: 0.6931\n",
      "Epoch [1/10], Step [1000/1044], Loss: 0.6931\n",
      "Epoch [2/10], Step [0/1044], Loss: 0.6931\n",
      "Epoch [2/10], Step [100/1044], Loss: 0.6931\n",
      "Epoch [2/10], Step [200/1044], Loss: 0.6931\n",
      "Epoch [2/10], Step [300/1044], Loss: 0.6931\n",
      "Epoch [2/10], Step [400/1044], Loss: 0.6931\n",
      "Epoch [2/10], Step [500/1044], Loss: 0.6931\n",
      "Epoch [2/10], Step [600/1044], Loss: 0.6931\n",
      "Epoch [2/10], Step [700/1044], Loss: 0.6931\n",
      "Epoch [2/10], Step [800/1044], Loss: 0.6931\n",
      "Epoch [2/10], Step [900/1044], Loss: 0.6931\n",
      "Epoch [2/10], Step [1000/1044], Loss: 0.6931\n",
      "Epoch [3/10], Step [0/1044], Loss: 0.6931\n",
      "Epoch [3/10], Step [100/1044], Loss: 0.6931\n",
      "Epoch [3/10], Step [200/1044], Loss: 0.6931\n",
      "Epoch [3/10], Step [300/1044], Loss: 0.6931\n",
      "Epoch [3/10], Step [400/1044], Loss: 0.6931\n",
      "Epoch [3/10], Step [500/1044], Loss: 0.6931\n",
      "Epoch [3/10], Step [600/1044], Loss: 0.6931\n",
      "Epoch [3/10], Step [700/1044], Loss: 0.6931\n",
      "Epoch [3/10], Step [800/1044], Loss: 0.6931\n",
      "Epoch [3/10], Step [900/1044], Loss: 0.6931\n",
      "Epoch [3/10], Step [1000/1044], Loss: 0.6931\n",
      "Epoch [4/10], Step [0/1044], Loss: 0.6931\n",
      "Epoch [4/10], Step [100/1044], Loss: 0.6931\n",
      "Epoch [4/10], Step [200/1044], Loss: 0.6931\n",
      "Epoch [4/10], Step [300/1044], Loss: 0.6931\n",
      "Epoch [4/10], Step [400/1044], Loss: 0.6931\n",
      "Epoch [4/10], Step [500/1044], Loss: 0.6931\n",
      "Epoch [4/10], Step [600/1044], Loss: 0.6931\n",
      "Epoch [4/10], Step [700/1044], Loss: 0.6931\n",
      "Epoch [4/10], Step [800/1044], Loss: 0.6931\n",
      "Epoch [4/10], Step [900/1044], Loss: 0.6931\n",
      "Epoch [4/10], Step [1000/1044], Loss: 0.6931\n",
      "Epoch [5/10], Step [0/1044], Loss: 0.6931\n",
      "Epoch [5/10], Step [100/1044], Loss: 0.6931\n",
      "Epoch [5/10], Step [200/1044], Loss: 0.6931\n",
      "Epoch [5/10], Step [300/1044], Loss: 0.6931\n",
      "Epoch [5/10], Step [400/1044], Loss: 0.6931\n",
      "Epoch [5/10], Step [500/1044], Loss: 0.6931\n",
      "Epoch [5/10], Step [600/1044], Loss: 0.6931\n",
      "Epoch [5/10], Step [700/1044], Loss: 0.6931\n",
      "Epoch [5/10], Step [800/1044], Loss: 0.6931\n",
      "Epoch [5/10], Step [900/1044], Loss: 0.6931\n",
      "Epoch [5/10], Step [1000/1044], Loss: 0.6931\n",
      "Epoch [6/10], Step [0/1044], Loss: 0.6931\n",
      "Epoch [6/10], Step [100/1044], Loss: 0.6931\n",
      "Epoch [6/10], Step [200/1044], Loss: 0.6931\n",
      "Epoch [6/10], Step [300/1044], Loss: 0.6931\n",
      "Epoch [6/10], Step [400/1044], Loss: 0.6931\n",
      "Epoch [6/10], Step [500/1044], Loss: 0.6931\n",
      "Epoch [6/10], Step [600/1044], Loss: 0.6931\n",
      "Epoch [6/10], Step [700/1044], Loss: 0.6931\n",
      "Epoch [6/10], Step [800/1044], Loss: 0.6931\n",
      "Epoch [6/10], Step [900/1044], Loss: 0.6931\n",
      "Epoch [6/10], Step [1000/1044], Loss: 0.6931\n",
      "Epoch [7/10], Step [0/1044], Loss: 0.6931\n",
      "Epoch [7/10], Step [100/1044], Loss: 0.6931\n",
      "Epoch [7/10], Step [200/1044], Loss: 0.6931\n",
      "Epoch [7/10], Step [300/1044], Loss: 0.6931\n",
      "Epoch [7/10], Step [400/1044], Loss: 0.6931\n",
      "Epoch [7/10], Step [500/1044], Loss: 0.6931\n",
      "Epoch [7/10], Step [600/1044], Loss: 0.6931\n",
      "Epoch [7/10], Step [700/1044], Loss: 0.6931\n",
      "Epoch [7/10], Step [800/1044], Loss: 0.6931\n",
      "Epoch [7/10], Step [900/1044], Loss: 0.6931\n",
      "Epoch [7/10], Step [1000/1044], Loss: 0.6931\n",
      "Epoch [8/10], Step [0/1044], Loss: 0.6931\n",
      "Epoch [8/10], Step [100/1044], Loss: 0.6931\n",
      "Epoch [8/10], Step [200/1044], Loss: 0.6931\n",
      "Epoch [8/10], Step [300/1044], Loss: 0.6931\n",
      "Epoch [8/10], Step [400/1044], Loss: 0.6931\n",
      "Epoch [8/10], Step [500/1044], Loss: 0.6931\n",
      "Epoch [8/10], Step [600/1044], Loss: 0.6931\n",
      "Epoch [8/10], Step [700/1044], Loss: 0.6931\n",
      "Epoch [8/10], Step [800/1044], Loss: 0.6931\n",
      "Epoch [8/10], Step [900/1044], Loss: 0.6931\n",
      "Epoch [8/10], Step [1000/1044], Loss: 0.6931\n",
      "Epoch [9/10], Step [0/1044], Loss: 0.6931\n",
      "Epoch [9/10], Step [100/1044], Loss: 0.6931\n",
      "Epoch [9/10], Step [200/1044], Loss: 0.6931\n",
      "Epoch [9/10], Step [300/1044], Loss: 0.6931\n",
      "Epoch [9/10], Step [400/1044], Loss: 0.6931\n",
      "Epoch [9/10], Step [500/1044], Loss: 0.6931\n",
      "Epoch [9/10], Step [600/1044], Loss: 0.6931\n",
      "Epoch [9/10], Step [700/1044], Loss: 0.6931\n",
      "Epoch [9/10], Step [800/1044], Loss: 0.6931\n",
      "Epoch [9/10], Step [900/1044], Loss: 0.6931\n",
      "Epoch [9/10], Step [1000/1044], Loss: 0.6931\n",
      "Epoch [10/10], Step [0/1044], Loss: 0.6931\n",
      "Epoch [10/10], Step [100/1044], Loss: 0.6931\n",
      "Epoch [10/10], Step [200/1044], Loss: 0.6931\n",
      "Epoch [10/10], Step [300/1044], Loss: 0.6931\n",
      "Epoch [10/10], Step [400/1044], Loss: 0.6931\n",
      "Epoch [10/10], Step [500/1044], Loss: 0.6931\n",
      "Epoch [10/10], Step [600/1044], Loss: 0.6931\n",
      "Epoch [10/10], Step [700/1044], Loss: 0.6931\n",
      "Epoch [10/10], Step [800/1044], Loss: 0.6931\n",
      "Epoch [10/10], Step [900/1044], Loss: 0.6931\n",
      "Epoch [10/10], Step [1000/1044], Loss: 0.6931\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# CustomDataset 클래스 정의\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dir_path_ball, dir_path_background, transform=None):\n",
    "        self.dir_path_ball = dir_path_ball\n",
    "        self.dir_path_background = dir_path_background\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 이미지 파일 경로와 라벨을 리스트로 만듭니다.\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # 라벨이 1인 이미지 (테니스공)\n",
    "        for filename in os.listdir(self.dir_path_ball):\n",
    "            if filename.endswith('.png'):  # .png 파일만 추가\n",
    "                self.image_paths.append(os.path.join(self.dir_path_ball, filename))\n",
    "                self.labels.append(1)\n",
    "        \n",
    "        # 라벨이 0인 이미지 (배경)\n",
    "        for filename in os.listdir(self.dir_path_background):\n",
    "            if filename.endswith('.png'):  # .png 파일만 추가\n",
    "                self.image_paths.append(os.path.join(self.dir_path_background, filename))\n",
    "                self.labels.append(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 이미지를 로드하고 라벨을 가져옵니다.\n",
    "        image = Image.open(self.image_paths[index])\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# 데이터셋 인스턴스화 및 DataLoader 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((30, 30)), # 이미지 크기 조정\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dir_path_ball = r'C:\\Users\\lwj01\\HowFastTennisBallIs\\novak_sinner_over_30\\cropped_ball\\augmentation'\n",
    "dir_path_background = r'C:\\Users\\lwj01\\HowFastTennisBallIs\\novak_sinner_over_30\\cropped_baseground'\n",
    "\n",
    "train_dataset = CustomDataset(\n",
    "    dir_path_ball=dir_path_ball,\n",
    "    dir_path_background=dir_path_background,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# 모델 인스턴스화 및 학습 준비\n",
    "model = BinaryClassificationCNN()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 과정\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # 데이터와 타겟을 GPU로 옮김 (GPU 사용 시)\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device).float().view(-1, 1)\n",
    "\n",
    "        # 순전파\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets.float())\n",
    "\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # 가중치 갱신\n",
    "        optimizer.step()\n",
    "\n",
    "        # 학습 진행 상황 출력\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb3f5e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_v2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4d2ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
