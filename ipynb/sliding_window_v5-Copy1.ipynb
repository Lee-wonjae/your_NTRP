{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "091ca947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db5bc6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# BasicBlock 클래스 정의\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = torch.relu(out)\n",
    "        return out\n",
    "\n",
    "# SmallResNet 클래스 정의\n",
    "class SmallResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1):\n",
    "        super(SmallResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=1)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=1)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def SmallResNet18():\n",
    "    return SmallResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "model = SmallResNet18().to(device)\n",
    "model = torch.load('model_v5.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be244836",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     40\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, filename)\n\u001b[1;32m---> 41\u001b[0m     score, location, window \u001b[38;5;241m=\u001b[39m detect_objects_per_image(model, image_path)\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Best Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Location: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m window \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[6], line 27\u001b[0m, in \u001b[0;36mdetect_objects_per_image\u001b[1;34m(model, image_path, window_size, step_size)\u001b[0m\n\u001b[0;32m     24\u001b[0m window_tensor \u001b[38;5;241m=\u001b[39m transform(window)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     25\u001b[0m output \u001b[38;5;241m=\u001b[39m model(window_tensor)\n\u001b[1;32m---> 27\u001b[0m score \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(output)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     28\u001b[0m window_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_x\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_y\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_score\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mfloat\u001b[39m(score\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 고유한 파일명 생성\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "directory = r'C:\\Users\\lwj01\\HowFastTennisBallIs\\novak_sinner_over_30'\n",
    "save_directory = r'C:\\Users\\lwj01\\HowFastTennisBallIs\\y_v5'  # 저장할 경로\n",
    "save_directory_over=r'C:\\Users\\lwj01\\HowFastTennisBallIs\\y_v5\\over'\n",
    "\n",
    "def sliding_window(image, step_size, window_size):\n",
    "    \"\"\"이미지 위에서 슬라이딩 윈도우를 생성하는 함수\"\"\"\n",
    "    for y in range(0, image.size[1] - window_size[1], step_size):\n",
    "        for x in range(0, image.size[0] - window_size[0], step_size):\n",
    "            yield (x, y, image.crop((x, y, x + window_size[0], y + window_size[1])))\n",
    "\n",
    "def detect_objects_per_image(model, image_path, window_size=(30, 30), step_size=10):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    transform = transforms.Compose([transforms.Resize(window_size), transforms.ToTensor()])\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_filename = os.path.basename(image_path).split('.')[0]  # 확장자를 제외한 파일 이름\n",
    "\n",
    "    for (x, y, window) in sliding_window(image, step_size, window_size):\n",
    "        window_tensor = transform(window).unsqueeze(0).to(device)\n",
    "        output = model(window_tensor)\n",
    "        \n",
    "        score = torch.sigmoid(output).item()\n",
    "        window_filename = f\"{image_filename}_x{x}_y{y}_score{float(score*100)}.jpg\"  # 고유한 파일명 생성\n",
    "\n",
    "        if score >= 0.5:\n",
    "            save_path = os.path.join(save_directory_over, window_filename)\n",
    "        else:\n",
    "            save_path = os.path.join(save_directory, window_filename)\n",
    "\n",
    "        window.save(save_path)\n",
    "\n",
    "# 모든 이미지에 대해 객체 탐지 실행\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(directory, filename)\n",
    "        score, location, window = detect_objects_per_image(model, image_path)\n",
    "        print(f\"Image: {filename}, Best Score: {score}, Location: {location}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b915a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
